{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60102b93-8e58-4d8a-ab48-15f3014bcc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import mne\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a560f4-d5d1-43b9-ad7f-0abda175c31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_min_num_of_file(dir):\n",
    "    print(f'========= The process of finding the optimal number of images for each stage has been started. =========')\n",
    "    print(f'========= During the process files of the supplied directory will be analysed. =========\\n')\n",
    "\n",
    "    all_files_in_dir = os.listdir(dir)\n",
    "    stages = [0, 0, 0, 0, 0, 0]\n",
    "\n",
    "    all_psg_files = []\n",
    "    all_hyp_files = []\n",
    "    checked = 0\n",
    "    annotation_desc_2_event_id = {\n",
    "        \"Sleep stage W\": 1,\n",
    "        \"Sleep stage 1\": 2,\n",
    "        \"Sleep stage 2\": 3,\n",
    "        \"Sleep stage 3\": 4,\n",
    "        \"Sleep stage 4\": 5,\n",
    "        \"Sleep stage R\": 6,\n",
    "    }\n",
    "\n",
    "    for file in all_files_in_dir:\n",
    "        if file[0] == '.':    # for ignoring hidden files in the directory\n",
    "            continue\n",
    "        parts = file.split(\"-\")\n",
    "        if parts[1] == \"PSG.edf\":\n",
    "            all_psg_files.append(file)\n",
    "        elif parts[1] == \"Hypnogram.edf\":\n",
    "            all_hyp_files.append(file)\n",
    "\n",
    "    for file in all_psg_files:\n",
    "        \n",
    "        current_psg_file = dir + \"/\" + file\n",
    "\n",
    "        hyp_file = file.split(\"-\")[0][:-2] + \"*\" + \"-Hypnogram.edf\"\n",
    "        possible_hyp_file = fnmatch.filter(all_hyp_files, hyp_file)\n",
    "\n",
    "        if possible_hyp_file:\n",
    "\n",
    "            current_hyp_file = dir + \"/\" + possible_hyp_file[0]\n",
    "\n",
    "            data = mne.io.read_raw_edf(current_psg_file, stim_channel=\"Event marker\", ifer_types=True, preload=True, verbose=False)\n",
    "\n",
    "            annot_train = mne.read_anotations(current_hyp_file)\n",
    "\n",
    "            annot_train.crop(annot_train[1][\"onset\"] - 30*60, annot_train[-2][\"onset\"] + 30*60)\n",
    "            data.set_annotations(annot_train, emit_warning=False)\n",
    "\n",
    "\n",
    "            events_train, _ = mne.events_from_annotations(\n",
    "                data, event_id=annotation_desc_2_event_id, chunk_duration=30.0, verbose=False\n",
    "            )\n",
    "\n",
    "            for event in events_train:\n",
    "                stages[event[2] - 1] += 1\n",
    "            \n",
    "            checked += 1\n",
    "\n",
    "            print(f'========= Files have been analysed {checked}/{len(all_psg_files)} =========', end=\"\\r\")\n",
    "        else:\n",
    "            print(f'\\n========= No such hypnogram file for {file} =========\\n')\n",
    "\n",
    "    print(f'\\n========= Analysing has been done. =========\\n')\n",
    "\n",
    "    i = 0\n",
    "    for stage in list(annotation_desc_2_event_id):\n",
    "        print(f'========= Number of files for {stage} is {stage[i]} =========')\n",
    "        i += 1\n",
    "\n",
    "    print(f'========= Minimum number of files for each stage is {min(stages)} =========')\n",
    "\n",
    "    return min(stages), max(stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "309c186f-d0d9-4208-93a4-eab3c7ae4dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_keeper(psg_file, hypnogram_file):\n",
    "    data = mne.io.read_raw_edf(psg_file, stim_channel=\"Event marker\", infer_types=True, preload=True)\n",
    "    annotations = mne.read_annotations(hypnogram_file)\n",
    "    return data, annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d198dc7e-561e-4c01-bb28-39dc8971bd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_sleep_stages(annotations):\n",
    "    sleep_stages = []\n",
    "    for i in annotations:\n",
    "        if i.get('desription') in sleep_stages:\n",
    "            pass\n",
    "        else:\n",
    "            sleep_stages.append(i.get('description'))\n",
    "    return sleep_stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61661e5b-ab01-4baf-955a-702b1ae6d0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_set_annotations(data, annotations):\n",
    "    annotations.crop(annotations[1][\"onset\"] - 30*60, annotations[-2][\"onset\"] + 30*60)\n",
    "    data.set_annotatios(annotations, emit_warning=False)\n",
    "\n",
    "    annotation_stage_id = {\n",
    "        \"Sleep stage W\": 1,\n",
    "        \"Sleep stage 1\": 2,\n",
    "        \"Sleep stage 2\": 3,\n",
    "        \"Sleep stage 3\": 4,\n",
    "        \"Sleep stage 4\": 5,\n",
    "        \"Sleep stage R\": 6,\n",
    "    }\n",
    "\n",
    "    events_train,_ = mne.events_from_annotations(\n",
    "        data, evet_id=annotation_stage_id, chunk_duration=30.0\n",
    "    )\n",
    "    return events_train, annotation_stage_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015c5311-16b4-4218-a8dd-60c62475ab88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directories(sleep_stages):\n",
    "\n",
    "    dir_name = \"dataset\"\n",
    "\n",
    "    if not os.path.isdir(dir_name):\n",
    "        main_dir = dir_name\n",
    "        train_dir = dir_name + \"/train\"\n",
    "        train_files_dir = []\n",
    "        for i in sleep_stages:\n",
    "            if i == \"Sleep stage ?\":\n",
    "                pass\n",
    "            else:\n",
    "                train_files_dir.append(dir_name + \"/train/\" + i)\n",
    "        \n",
    "        test_dir = \"dataset/test\"\n",
    "        test_files_dir = []\n",
    "        for i in sleep_stages:\n",
    "            if i == 'Sleep stage ?':\n",
    "                pass\n",
    "            else:\n",
    "                test_files_dir.append(dir_name + \"/test/\" + i)\n",
    "\n",
    "        directories = (main_dir, train_dir, train_files_dir)\n",
    "\n",
    "        for directory in directories:\n",
    "            if isinstance(directory, list):  # Checking if the directory variable is a list\n",
    "                for sub_directory in directory:\n",
    "                    if os.path.isdir(sub_directory):\n",
    "                        pass\n",
    "                    else:\n",
    "                        try:\n",
    "                            os.mkdir(sub_directory)\n",
    "                        except FileExistsError:\n",
    "                            print(f\"Folder '{sub_directory}' is already exists.\")\n",
    "            else:\n",
    "\n",
    "                if os.path.isdir(directory):\n",
    "                    pass\n",
    "                else:\n",
    "                    try:\n",
    "                        os.mkdir(directory)\n",
    "                    except FileExistsError:\n",
    "                        print(f\"Folder '{directory}' is already exists.\")\n",
    "\n",
    "        print('========= Directories have been created. =========')\n",
    "    else:\n",
    "        print(f'========= Directory {dir_name} already exists. =========')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "038a90a2-99c6-4dd4-aaf7-36d7e147f103",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_images(data, events_train, annotations, annotation_stage_id, psg_file, optim_num_imgs, ctrl_imgs):\n",
    "    \n",
    "    data.set_annotations(None) # to turn off the coloring of annotations\n",
    "\n",
    "    for event_for_image in events_train:\n",
    "        \n",
    "        start_time = int(event_for_image[0] / data.info.get('sfreq')) # moment of the signal part on the graph\n",
    "\n",
    "        if ctrl_imgs[event_for_image[2] - 1] < optim_num_imgs:\n",
    "\n",
    "            fig = data.plot(\n",
    "                start = start_time,\n",
    "                duration = 30,\n",
    "                scalings = dict(eeg=1e-4),\n",
    "                n_channels = 1,\n",
    "                order = [0, 1],\n",
    "\n",
    "                show_scrollbars = False,\n",
    "                show = False,\n",
    "                show_scalebars = False\n",
    "            )\n",
    "            for one_ax in fig.axis:\n",
    "                one_ax.axis('off')\n",
    "\n",
    "            stage_list = list(annotation_stage_id.keys())\n",
    "            stage_id = list(annotation_stage_id.values()).index(event_for_image[2])\n",
    "            path_for_image = 'dataset/train/' + stage_list[stage_id] + '/' + stage_list[stage_id] + \\\n",
    "                                '_' + psg_file.split(\"-\")[0] + '_' + str(start_time)\n",
    "\n",
    "            fig.savefig(path_for_image)\n",
    "            plt.close(fig)\n",
    "            ctrl_imgs[event_for_image[2] - 1] += 1\n",
    "\n",
    "    print(f'\\n Images have been prepared for {psg_file.split(\"-\")[0][0:-2]}. \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f02a102d-36a4-477d-9972-6084d4b34e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_grayscale(): # Not necessary, because argument color_mode in the keras.utils.image_dataset_from_directory helps to convert images in grayscale\n",
    "    path_for_image = \"dataset/train\"\n",
    "    for folder in os.listdir(path_for_image):\n",
    "        current = path_for_image + \"/\" + folder\n",
    "        files = os.listdir(current)\n",
    "        for file in files:\n",
    "            if file[0] == '.':\n",
    "                pass\n",
    "            else:\n",
    "                current_file_path = current + \"/\" + file\n",
    "                img = Image.open(current_file_path)\n",
    "                img = img.convert('L')\n",
    "                img.save(current_file_path)\n",
    "    print('========= Files have been converted. =========')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca0c3280-c9bb-4903-878f-5375d660c6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_create(files_directory, optim_num_imgs):\n",
    "\n",
    "    all_files = os.listdir(files_directory)\n",
    "    not_processed_files = []\n",
    "    all_psg_files = []\n",
    "    all_hyp_files = []\n",
    "\n",
    "    ctrl_imgs = 6*[0] # List for the number of images (for 6 stages)\n",
    "\n",
    "    for file in all_files:\n",
    "\n",
    "        if file[0] == '.': # for ignoring hidden files in the directory\n",
    "            continue\n",
    "\n",
    "        parts = file.split(\"-\")\n",
    "\n",
    "        if parts[1] == \"PSG.edf\":\n",
    "            all_psg_files.append(file)\n",
    "        elif parts[1] == \"Hypnogram.edf\":\n",
    "            all_hyp_files.append(file)\n",
    "\n",
    "    # for controlling status progress\n",
    "    old_process_percentage = 0\n",
    "    process_percentage = 0\n",
    "    iteration = 0\n",
    "\n",
    "    for psg_file in all_psg_files:\n",
    "\n",
    "        hyp_file = psg_file.split(\"-\")[0][:-2] + \"*\" + \"-Hypnogram.edf\"\n",
    "        possible_hyp = fnmatch.filter(all_hyp_files, hyp_file)\n",
    "\n",
    "        if possible_hyp:\n",
    "\n",
    "            hyp_file = possible_hyp[0]\n",
    "\n",
    "            print(f\"\\n================ Files currently being processed: {psg_file}, {hyp_file} ================\")\n",
    "\n",
    "            psg_file_path = files_directory + \"/\" + psg_file\n",
    "            hyp_file_path = files_directory + \"/\" + hyp_file\n",
    "\n",
    "            data, annotations = file_keeper(psg_file_path, hyp_file_path)\n",
    "            print(\"======== Got data and annotations. ========\")\n",
    "\n",
    "            events_train, annotation_stage_id = crop_set_annotations(data, annotations)\n",
    "            print(\"======== Annotations cropped and set. ========\")\n",
    "\n",
    "            create_directories(annotation_stage_id)\n",
    "\n",
    "            create_images(data, events_train, annotation_stage_id, psg_file, optim_num_imgs, ctrl_imgs)\n",
    "\n",
    "        else:\n",
    "            not_processed_file = psg_file.split(\"-\")[0][:-2] # Get number of the candidate, i.e. SC4812\n",
    "            print(f\"No such hypnogram file for {not_processed_file}\")\n",
    "            not_processed_files.append(not_processed_file)\n",
    "\n",
    "        iteration += 1\n",
    "\n",
    "        process_percentage = round(iteration / len(all_psg_files) * 100)  # progress controlling\n",
    "\n",
    "        if process_percentage != old_process_percentage:\n",
    "            print(f\"======== Extracting images from PSG signals: {process_percentage}% ========\", end=\"\\r\")\n",
    "\n",
    "        old_process_percentage = process_percentage\n",
    "\n",
    "    print(f\"======== Extracting images from PSG signals: {process_percentage}% ========\", end=\"\\r\")\n",
    "    # print(\"Starting converting images to grayscale.\")  # Not necessary\n",
    "    # convert_to_grayscale()\n",
    "    print(\"Images for the dataset have been created.\")\n",
    "    if not_processed_files:\n",
    "        print(f\"Files that weren't processed: {not_processed_files}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c841193-4ab6-4729-b2fd-34fae8cc104c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dir): # Give the path for yours dataset for splitting\n",
    "\n",
    "    print(f\"======== The process of the dataset splitting has been started. ========\")\n",
    "\n",
    "    dir_train = dir + \"/train\"\n",
    "    train_folders = os.listdir(dir_train)\n",
    "\n",
    "    for folder in train_folders:\n",
    "        current_folder = dir_train + \"/\" + folder\n",
    "        number_of_files_to_move = round(0.2 * len(os.listdir(current_folder)))\n",
    "        i = 1\n",
    "        while i <= number_of_files_to_move:\n",
    "            files_in_folder = os.listdir(current_folder)\n",
    "            chosen_file = files_in_folder[random.randint(0, len(files_in_folder) - 1)]\n",
    "\n",
    "            path_from = current_folder + \"/\" + chosen_file\n",
    "            path_to = dir + \"/test/\" + folder + \"/\" + chosen_file\n",
    "\n",
    "            shutil.move(path_from, path_to)\n",
    "            i += 1\n",
    "\n",
    "        print(f\"Number of moved files to the test/{folder}: {number_of_files_to_move}\")\n",
    "\n",
    "    print(\"Dataset has been splitted.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020fa51e-27b3-49be-85e0-f29e2ddebdee",
   "metadata": {},
   "source": [
    "## PREDICTING DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df17849b-33e7-4665-a849-13de73852d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir_and_img_pred(name_predict_sig, data, events_train, annotations, annotation_stage_id, psg_file):\n",
    "\n",
    "    # Creating a directory\n",
    "\n",
    "    dir_name = \"dataset_predict\"\n",
    "\n",
    "    name_predict_sig = dir_name + \"/\" + name_predict_sig # creating full path of the folder\n",
    "\n",
    "    directories = (dir_name, name_predict_sig)\n",
    "\n",
    "    for directory in directories:\n",
    "        if os.path.isdir(directory):\n",
    "            pass\n",
    "        else:\n",
    "            try:\n",
    "                os.mkdir(directory)\n",
    "                print(f\"======== Directory {directory} has been created. ========\")\n",
    "            except FileExistsError:\n",
    "                print(f\"Folder '{directory}' already exists.\")\n",
    "\n",
    "    # Creating an image\n",
    "\n",
    "    data.set_annotations(None) # to turn off the coloring of annotations\n",
    "\n",
    "    i = 0\n",
    "    old_process_percentage = 0\n",
    "    process_percentage = 0\n",
    "\n",
    "    for event_for_image in events_train:\n",
    "\n",
    "        process_percentage = round(i / len(events_train) * 100) # process controlling\n",
    "        if process_percentage != old_process_percentage:\n",
    "            print(f\"======== Extracting images from PSG signals: {process_percentage}% ========\", end=\"\\r\")\n",
    "\n",
    "        start_time = int(event_for_image[0] / data.info.get('sfreq')) # start moment of the signal part on the graph\n",
    "\n",
    "        fig = data.plot(\n",
    "            start=start_time,\n",
    "            duration=30,\n",
    "            scalings=dict(eeg=1e-4),\n",
    "            n_channels=1,\n",
    "            order=[0, 1],\n",
    "\n",
    "            show_scrollbars=False,\n",
    "            show=False,\n",
    "            show_scalebars=False\n",
    "        )\n",
    "        for one_ax in fig.axes:\n",
    "            one_ax.axis('off')\n",
    "\n",
    "        stage_list = list(annotation_stage_id.keys())\n",
    "        stage_id = list(annotation_stage_id.values()).index(event_for_image[2])\n",
    "        path_for_image = name_predict_sig + '/' + stage_list[stage_id] + \\\n",
    "                        '_' + psg_file.split(\"-\")[0] + '_' + str(start_time)\n",
    "\n",
    "        fig.savefig(path_for_image)\n",
    "\n",
    "        plt.close(fig)\n",
    "\n",
    "        old_process_percentage = process_percentage\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    print(f\"\\n Images have been preapred for {psg_file.split(\"-\")[0][0:-2]}.\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f658c2-1355-4369-8b49-dfb78fe84bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_predict_dataset(files_directory):\n",
    "\n",
    "    print(f\"======== The process of predict dataset has been started. ========\")\n",
    "    print(f\"======== During the process files of the supplied directory will be processed. ========\\n\")\n",
    "\n",
    "    all_files = os.listdir(files_directory)\n",
    "    not_processed_files = []\n",
    "    all_psg_files = []\n",
    "    all_hyp_files = []\n",
    "\n",
    "    for file in all_files:\n",
    "        if file[0] == '.': # for ignoring hidden files\n",
    "            continue\n",
    "        parts = file.split(\"-\")\n",
    "        if parts[1] == \"PSG.edf\":\n",
    "            all_psg_files.append(file)\n",
    "        elif parts[1] == \"Hypnogram.edf\":\n",
    "            all_hyp_files.append(file)\n",
    "\n",
    "    old_process_percentage = 0\n",
    "    process_percentage = 0\n",
    "\n",
    "    iteration = 0\n",
    "\n",
    "    for psg_file in all_psg_files:\n",
    "\n",
    "        process_percentage = round(iteration / len(all_psg_files) * 100) # process controlling\n",
    "        if process_percentage != old_process_percentage:\n",
    "            print(f\"\\n======== Extracting images from PSG signals: {process_percentage}% ========\\n\")\n",
    "\n",
    "        hyp_file = psg_file.split(\"-\")[0][:-2] + \"*\" + \"-Hypnogram.edf\"\n",
    "        possible_hyp = fnmatch.filter(all_hyp_files, hyp_file)\n",
    "\n",
    "        if possible_hyp:\n",
    "            hyp_file = possible_hyp[0]\n",
    "\n",
    "            print(f\"======== Files currently being processed: {psg_file}, {hyp_file} ========\")\n",
    "\n",
    "            psg_file_path = files_directory + \"/\" + psg_file\n",
    "            hyp_file_path = files_directory + \"/\" + hyp_file\n",
    "\n",
    "            data, annotations = file_keeper(psg_file_path, hyp_file_path)\n",
    "            print(\"======== Got data and annotations. ========\")\n",
    "\n",
    "            events_train, annotation_stage_id = crop_set_annotations(data, annotations)\n",
    "            print(\"======== Annotations cropped and set. ========\")\n",
    "\n",
    "            name_predict_sig = psg_file.split(\"-\")[0][:-2]\n",
    "            create_dir_and_img_pred(name_predict_sig, data, events_train, annotations, annotation_stage_id, psg_file)\n",
    "\n",
    "        else:\n",
    "            not_processed_file = psg_file.split(\"-\")[0][:-2] # Gets number of the candidate, i.e. SC4812\n",
    "            print(f\"No such hypnogram file for {not_processed_file}\")\n",
    "            not_processed_files.append(not_processed_file)\n",
    "\n",
    "        old_process_percentage = process_percentage\n",
    "\n",
    "        iteration += 1\n",
    "\n",
    "    print(f\"\\n======== Extracting images from PSG signals: {process_percentage}% ========\\n\")\n",
    "\n",
    "\n",
    "    # Not necessary\n",
    "    # print(\"Starting converting images to grayscale.\")\n",
    "    # path_for_image_dir = \"dataset_predict\"\n",
    "    # for folder in os.listdir(path_for_image_dir):\n",
    "    #     current = path_for_image_dir + \"/\" + folder\n",
    "    #     files = os.listdir(current)\n",
    "    #     for file in files:\n",
    "    #         current_file_path = current + \"/\" + file\n",
    "    #         if file[0] == '.':\n",
    "    #             pass\n",
    "    #         else:\n",
    "    #             img = Image.open(current_file_path)\n",
    "    #             img = img.convert('L')\n",
    "    #             img.save(current_file_path)\n",
    "    # print(\"======== Files have been converted. ========\")\n",
    "\n",
    "    print(\"======== Images for the dataset have been created. ========\")\n",
    "\n",
    "    if not_processed_files:\n",
    "        print(f\"Files that weren't processed: {not_processed_files}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
