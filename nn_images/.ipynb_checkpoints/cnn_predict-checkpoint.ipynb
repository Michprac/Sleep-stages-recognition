{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edff2da4-c84c-40f2-a43c-6f5759a4137e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing import image\n",
    "import fnmatch\n",
    "import matplotlib.pyplot as plt\n",
    "import mne, os\n",
    "\n",
    "from cnn_prepare_dataset import file_keeper, crop_set_annotations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3cd0e7-50b1-4eae-b238-43913ff242d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hypnograms(events, times_events, sfreq, img_folder_path, cnn, annotation_stage_id, training_set):\n",
    "\n",
    "    # Coordinates for true hypnogram and predicted respectively\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    x_pred = []\n",
    "    y_pred = []\n",
    "\n",
    "    percent = 0\n",
    "    correct_predict = 0\n",
    "    true_list = 6*[0] # List for true numbers of the each stage, based on the annotation_stage_id\n",
    "    correct_predict_list = 6*[0] # List of the correct predictions for the each stage, based on the annotation_stage_id\n",
    "\n",
    "    stages_names_list = list(annotation_stage_id.keys())\n",
    "    stages_id_list = list(annotation_stage_id.values())\n",
    "\n",
    "    for iteration in range(1, len(times_events)):\n",
    "\n",
    "        start = int(times_events[iteration - 1][0] / sfreq)\n",
    "        duration = int(times_events[iteration][0] / sfreq) - start\n",
    "        stage_id = times_events[iteration - 1][2]\n",
    "\n",
    "        current_stage_name = stages_names_list[stages_id_list.index(stage_id)]\n",
    "\n",
    "        x.append(start)\n",
    "        y.append(current_stage_name)\n",
    "        x.append(start + duration)\n",
    "        y.append(current_stage_name)\n",
    "\n",
    "        image_name = \"*\" + str(start) + \".png\"  # image name of the signal for specific PSG folder in the dataset_predict\n",
    "        possible_image = fnmatch.filter(os.listdir(img_folder_path), image_name)[0]\n",
    "\n",
    "        if not possible_image:\n",
    "            print(f\"Possible image file {image_name} hasn't been found.\")\n",
    "            continue\n",
    "\n",
    "        true_list[stage_id - 1] += 1  # counting stage elements\n",
    "\n",
    "        # print(f\"Image that is currently being processed: {possible_image}, start time: {start}\")\n",
    "\n",
    "        path_possible_img = img_folder_path + \"/\" + possible_image\n",
    "\n",
    "        expan_dim_image = image.load_img(path_possible_img, color_mode='grayscale', target_size=(800, 800))\n",
    "        expan_dim_image = image.img_to_array(expan_dim_image)\n",
    "        expan_dim_image = np.expand_dims(expan_dim_image, axis=0)\n",
    "        predict_res = cnn.predict(expan_dim_image)\n",
    "        \n",
    "        # print(f\"Predicted raw result: {predict_res}\")\n",
    "        # print(f\"Class indexes: {training_set.class_indices}\")\n",
    "\n",
    "        index_predict = list(predict_res[0])\n",
    "        # print(index_predict)\n",
    "\n",
    "        \n",
    "        predicted_value = np.argmax(index_predict)   # index\n",
    "\n",
    "        prediction_main_list = list(training_set.class_indices.keys())\n",
    "        prediction_id_main_list = list(training_set.class_indices.values())\n",
    "        \n",
    "        predicted_stage_name = prediction_main_list[predicted_value] # index of the current sleep stage in the prediction list\n",
    "        id_stage_predict = stages_names_list.index(predicted_stage_name) + 1\n",
    "        \n",
    "        # print(f\"Predicted value - {id_stage_predict}/{stage_id}\")\n",
    "\n",
    "        if id_stage_predict == stage_id:\n",
    "            correct_predict_list[stage_id-1] += 1\n",
    "\n",
    "        x_pred.append(start)\n",
    "        y_pred.append(predicted_stage_name)\n",
    "        x_pred.append(start + duration)\n",
    "        y_pred.append(predicted_stage_name)\n",
    "\n",
    "    print(\"======== Coordinates for true and predicted hypnogram have been received. ========\")\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # Hypnogram plotting\n",
    "\n",
    "    stages_names_for_plot = {\n",
    "        \"Sleep stage 4\": 0,\n",
    "        \"Sleep stage 3\": 1,\n",
    "        \"Sleep stage 2\": 2,\n",
    "        \"Sleep stage 1\": 3,\n",
    "        \"Sleep stage R\": 4,        \n",
    "        \"Sleep stage W\": 5\n",
    "    }\n",
    "\n",
    "    positions_of_labels = [0, 1, 2, 3, 4, 5]\n",
    "    y_true_data_plot = [stages_names_for_plot[elem] for elem in y]\n",
    "    y_pred_data_plot = [stages_names_for_plot[elem] for elem in y_pred]\n",
    "\n",
    "    plt.rcParams['font.family'] = 'Times New Roman'\n",
    "    plt.rcParams['font.size'] = 15\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig.set_figwidth(18)\n",
    "    fig.set_figheight(10)\n",
    "\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(x, y_true_data_plot, '-b', linewidth='1', label=\"True hypnogram\")\n",
    "    plt.yticks(positions_of_labels, stages_names_for_plot)\n",
    "    plt.xticks([])\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Sleep stage')\n",
    "    plt.title(f\"Hypnograms for {img_folder_path[-7:]}\")\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(x_pred, y_pred_data_plot, '-g', linewidth='1', label=\"Predicted hypnogram\")\n",
    "    plt.yticks(positions_of_labels, stages_names_for_plot)\n",
    "    plt.xticks([])\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Sleep stage')\n",
    "    plt.legend()\n",
    "\n",
    "    hypnogram_folder = img_folder_path + \"/\" + \"hypnogram_info\" + img_folder_path[-6:]\n",
    "    if not os.path.isdir(hypnogram_folder):\n",
    "        os.mkdir(hypnogram_folder)\n",
    "\n",
    "    path_save_img = hypnogram_folder + f\"/hypnogram_{img_folder_path[-6:]}\"\n",
    "    plt.savefig(path_save_img, bbox_inches='tight', pad_inches=0)\n",
    "\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Creating confusion map\n",
    "\n",
    "    \n",
    "    for elem in y_true_data_plot:\n",
    "        elem += 1\n",
    "        \n",
    "    for elem in y_pred_data_plot:\n",
    "        elem += 1\n",
    "    \n",
    "    path_save_img = hypnogram_folder + f\"/confusion_map_{img_folder_path[-6:]}\"\n",
    "    map = create_confusion_matrix(y_true_data_plot, y_pred_data_plot, path_save_img)\n",
    "\n",
    "\n",
    "    # Percentage of predictions\n",
    "    try:\n",
    "        percent = round(sum(correct_predict_list)/sum(true_list) * 100, 2)\n",
    "    except ZeroDivisionError:\n",
    "        percent = 0\n",
    "\n",
    "    info = f\"All prediction results for {img_folder_path[-6:]}: {sum(correct_predict_list)}/{sum(true_list)} \\\n",
    "                    ({percent}%)\\n\"\n",
    "\n",
    "    path_for_txt = hypnogram_folder + f\"/predict_info_{img_folder_path[-6:]}.txt\"\n",
    "    with open(path_for_txt, \"w\") as file:\n",
    "        file.write(info)\n",
    "\n",
    "    print(info)\n",
    "\n",
    "    for iteration in range(len(correct_predict_list)):\n",
    "        try:\n",
    "            percent = round(correct_predict_list[iteration]/true_list[iteration] * 100, 2)\n",
    "        except ZeroDivisionError:\n",
    "            if correct_predict_list[iteration] == true_list[iteration]:\n",
    "                percent = 100\n",
    "            else:\n",
    "                percent = 0\n",
    "        info = f\"Prediction results for {stages_names_list[iteration]}: {correct_predict_list[iteration]}/{true_list[iteration]} \\\n",
    "                    ({percent}%)\\n\"\n",
    "        print(info)\n",
    "\n",
    "        with open(path_for_txt, \"a\") as file:\n",
    "            file.write(info)\n",
    "    \n",
    "    print(f\"======== Hypnogram {img_folder_path[-7:]} has been created. ========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e78047-fdb0-4036-a551-8e1ed3112741",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predict_create_hypns(cnn, dir_edf_files_predict, training_set):\n",
    "\n",
    "    dir_predict_dataset = \"dataset_predict\"\n",
    "\n",
    "    if not os.path.isdir(dir_predict_dataset):\n",
    "        print(\"Prediction dataset hasn't been found. Impossible to make a prediction.\")\n",
    "        return\n",
    "\n",
    "    if not cnn:\n",
    "        cnn = tf.keras.models.load_model('models/exit_model.keras')\n",
    "        \n",
    "    print(f\"Summary for cnn model '{model_path}':\\n\")\n",
    "    cnn.summary()\n",
    "\n",
    "    for folder in os.listdir(dir_predict_dataset):\n",
    "\n",
    "        curr_path = dir_predict_dataset + \"/\" + folder\n",
    "\n",
    "        psg_file = folder + \"*\"  # name of the true psg signal files (psg and hyp) in the dir_edf_files_predict\n",
    "        possible_psg_files = fnmatch.filter(os.listdir(dir_edf_files_predict), psg_file)\n",
    "\n",
    "        psg_file_path = \"\"\n",
    "        hyp_file_path = \"\"\n",
    "        for file in possible_psg_files:\n",
    "            if file.split('-')[1][0] == \"H\":\n",
    "                hyp_file_path = dir_edf_files_predict + \"/\" + file\n",
    "            else:\n",
    "                psg_file_path = dir_edf_files_predict + \"/\" + file\n",
    "\n",
    "        data, annotations = file_keeper(psg_file_path, hyp_file_path)\n",
    "        sfreq = data.info.get('sfreq')\n",
    "        events_from_the_file, event_id_info, annotations_stage_id = crop_set_annotations(data, annotations)\n",
    "\n",
    "        tmax = 30.0 - 1.0 / data.info[\"sfreq\"]\n",
    "        epochs_from_the_file = mne.Epochs(\n",
    "            raw=data,\n",
    "            events=events_from_the_file,\n",
    "            event_id=event_id_info,\n",
    "            tmin=0.0,\n",
    "            tmax=tmax,\n",
    "            baseline=None,\n",
    "            verbose=False\n",
    "        )\n",
    "        events = epochs_from_the_file.get_data(picks=[0])\n",
    "        times_events = epochs_from_the_file.events\n",
    "\n",
    "        print(f\"Current path: {curr_path}\")\n",
    "        create_hypnograms(events, times_events, sfreq, curr_path, cnn, annotations_stage_id, training_set)\n",
    "\n",
    "    print(\"All hypnograms have been created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32cf84ee-7d02-4926-be5a-ff7702cb13ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "def create_confusion_matrix(true_array, prediction_array, path_save_img=''):\n",
    "    labels_stages = [1, 2, 3, 4, 5, 6]\n",
    "    result = confusion_matrix(true_array, prediction_array, labels=labels_stages)\n",
    "    print(f\"\\nConfusion matrix:\\n{result}\\n\")\n",
    "\n",
    "    table = pd.DataFrame(result, range(len(labels_stages)), range(len(labels_stages)))\n",
    "    fig = plt.figure()\n",
    "    map = sn.heatmap(table, annot=True, fmt='g')\n",
    "\n",
    "    if path_save_img:\n",
    "        plt.savefig(path_save_img)\n",
    "    else:\n",
    "        plt.show()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053881a6-cf51-4a0d-bb20-f0bd91693894",
   "metadata": {},
   "source": [
    "# EXIT CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf00099d-c34a-42c1-9cc2-7a681f5b0e5a",
   "metadata": {},
   "source": [
    "## PREDICTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048ae64b-e81e-448f-a7f5-cbec7eb18a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_edf_files_predict = \"edf_files/x_test_y_test\"\n",
    "model_path = 'models/exit_model.keras'\n",
    "make_predict_create_hypns(_, dir_edf_files_predict, training_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
