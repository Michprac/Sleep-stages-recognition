{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60102b93-8e58-4d8a-ab48-15f3014bcc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import mne\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a560f4-d5d1-43b9-ad7f-0abda175c31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_min_num_of_file(dir):\n",
    "    print(f'========= The process of finding the optimal number of images for each stage has been started. =========')\n",
    "    print(f'========= During the process files of the supplied directory will be analysed. =========\\n')\n",
    "\n",
    "    all_files_in_dir = os.listdir(dir)\n",
    "    stages = [0, 0, 0, 0, 0, 0]\n",
    "\n",
    "    all_psg_files = []\n",
    "    all_hyp_files = []\n",
    "    checked = 0\n",
    "    annotation_desc_2_event_id = {\n",
    "        \"Sleep stage W\": 1,\n",
    "        \"Sleep stage 1\": 2,\n",
    "        \"Sleep stage 2\": 3,\n",
    "        \"Sleep stage 3\": 4,\n",
    "        \"Sleep stage 4\": 5,\n",
    "        \"Sleep stage R\": 6,\n",
    "    }\n",
    "\n",
    "    for file in all_files_in_dir:\n",
    "        if file[0] == '.':    # for ignoring hidden files in the directory\n",
    "            continue\n",
    "        parts = file.split(\"-\")\n",
    "        if parts[1] == \"PSG.edf\":\n",
    "            all_psg_files.append(file)\n",
    "        elif parts[1] == \"Hypnogram.edf\":\n",
    "            all_hyp_files.append(file)\n",
    "\n",
    "    for file in all_psg_files:\n",
    "        \n",
    "        current_psg_file = dir + \"/\" + file\n",
    "\n",
    "        hyp_file = file.split(\"-\")[0][:-2] + \"*\" + \"-Hypnogram.edf\"\n",
    "        possible_hyp_file = fnmatch.filter(all_hyp_files, hyp_file)\n",
    "\n",
    "        if possible_hyp_file:\n",
    "\n",
    "            current_hyp_file = dir + \"/\" + possible_hyp_file[0]\n",
    "\n",
    "            data = mne.io.read_raw_edf(current_psg_file, stim_channel=\"Event marker\", ifer_types=True, preload=True, verbose=False)\n",
    "\n",
    "            annot_train = mne.read_anotations(current_hyp_file)\n",
    "\n",
    "            annot_train.crop(annot_train[1][\"onset\"] - 30*60, annot_train[-2][\"onset\"] + 30*60)\n",
    "            data.set_annotations(annot_train, emit_warning=False)\n",
    "\n",
    "\n",
    "            events_train, _ = mne.events_from_annotations(\n",
    "                data, event_id=annotation_desc_2_event_id, chunk_duration=30.0, verbose=False\n",
    "            )\n",
    "\n",
    "            for event in events_train:\n",
    "                stages[event[2] - 1] += 1\n",
    "            \n",
    "            checked += 1\n",
    "\n",
    "            print(f'========= Files have been analysed {checked}/{len(all_psg_files)} =========', end=\"\\r\")\n",
    "        else:\n",
    "            print(f'\\n========= No such hypnogram file for {file} =========\\n')\n",
    "\n",
    "    print(f'\\n========= Analysing has been done. =========\\n')\n",
    "\n",
    "    i = 0\n",
    "    for stage in list(annotation_desc_2_event_id):\n",
    "        print(f'========= Number of files for {stage} is {stage[i]} =========')\n",
    "        i += 1\n",
    "\n",
    "    print(f'========= Minimum number of files for each stage is {min(stages)} =========')\n",
    "\n",
    "    return min(stages), max(stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "309c186f-d0d9-4208-93a4-eab3c7ae4dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_keeper(psg_file, hypnogram_file):\n",
    "    data = mne.io.read_raw_edf(psg_file, stim_channel=\"Event marker\", infer_types=True, preload=True)\n",
    "    annotations = mne.read_annotations(hypnogram_file)\n",
    "    return data, annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d198dc7e-561e-4c01-bb28-39dc8971bd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_sleep_stages(annotations):\n",
    "    sleep_stages = []\n",
    "    for i in annotations:\n",
    "        if i.get('desription') in sleep_stages:\n",
    "            pass\n",
    "        else:\n",
    "            sleep_stages.append(i.get('description'))\n",
    "    return sleep_stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61661e5b-ab01-4baf-955a-702b1ae6d0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_set_annotations(data, annotations):\n",
    "    annotations.crop(annotations[1][\"onset\"] - 30*60, annotations[-2][\"onset\"] + 30*60)\n",
    "    data.set_annotatios(annotations, emit_warning=False)\n",
    "\n",
    "    annotation_stage_id = {\n",
    "        \"Sleep stage W\": 1,\n",
    "        \"Sleep stage 1\": 2,\n",
    "        \"Sleep stage 2\": 3,\n",
    "        \"Sleep stage 3\": 4,\n",
    "        \"Sleep stage 4\": 5,\n",
    "        \"Sleep stage R\": 6,\n",
    "    }\n",
    "\n",
    "    events_train,_ = mne.events_from_annotations(\n",
    "        data, evet_id=annotation_stage_id, chunk_duration=30.0\n",
    "    )\n",
    "    return events_train, annotation_stage_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015c5311-16b4-4218-a8dd-60c62475ab88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directories(sleep_stages):\n",
    "\n",
    "    dir_name = \"dataset\"\n",
    "\n",
    "    if not os.path.isdir(dir_name):\n",
    "        main_dir = dir_name\n",
    "        train_dir = dir_name + \"/train\"\n",
    "        train_files_dir = []\n",
    "        for i in sleep_stages:\n",
    "            if i == \"Sleep stage ?\":\n",
    "                pass\n",
    "            else:\n",
    "                train_files_dir.append(dir_name + \"/train/\" + i)\n",
    "        \n",
    "        test_dir = \"dataset/test\"\n",
    "        test_files_dir = []\n",
    "        for i in sleep_stages:\n",
    "            if i == 'Sleep stage ?':\n",
    "                pass\n",
    "            else:\n",
    "                test_files_dir.append(dir_name + \"/test/\" + i)\n",
    "\n",
    "        directories = (main_dir, train_dir, train_files_dir)\n",
    "\n",
    "        for directory in directories:\n",
    "            if isinstance(directory, list):  # Checking if the directory variable is a list\n",
    "                for sub_directory in directory:\n",
    "                    if os.path.isdir(sub_directory):\n",
    "                        pass\n",
    "                    else:\n",
    "                        try:\n",
    "                            os.mkdir(sub_directory)\n",
    "                        except FileExistsError:\n",
    "                            print(f\"Folder '{sub_directory}' is already exists.\")\n",
    "            else:\n",
    "\n",
    "                if os.path.isdir(directory):\n",
    "                    pass\n",
    "                else:\n",
    "                    try:\n",
    "                        os.mkdir(directory)\n",
    "                    except FileExistsError:\n",
    "                        print(f\"Folder '{directory}' is already exists.\")\n",
    "\n",
    "        print('========= Directories have been created. =========')\n",
    "    else:\n",
    "        print(f'========= Directory {dir_name} already exists. =========')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "038a90a2-99c6-4dd4-aaf7-36d7e147f103",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_images(data, events_train, annotations, annotation_stage_id, psg_file, optim_num_imgs, ctrl_imgs):\n",
    "    \n",
    "    data.set_annotations(None) # to turn off the coloring of annotations\n",
    "\n",
    "    for event_for_image in events_train:\n",
    "        \n",
    "        start_time = int(event_for_image[0] / data.info.get('sfreq')) # moment of the signal part on the graph\n",
    "\n",
    "        if ctrl_imgs[event_for_image[2] - 1] < optim_num_imgs:\n",
    "\n",
    "            fig = data.plot(\n",
    "                start = start_time,\n",
    "                duration = 30,\n",
    "                scalings = dict(eeg=1e-4),\n",
    "                n_channels = 1,\n",
    "                order = [0, 1],\n",
    "\n",
    "                show_scrollbars = False,\n",
    "                show = False,\n",
    "                show_scalebars = False\n",
    "            )\n",
    "            for one_ax in fig.axis:\n",
    "                one_ax.axis('off')\n",
    "\n",
    "            stage_list = list(annotation_stage_id.keys())\n",
    "            stage_id = list(annotation_stage_id.values()).index(event_for_image[2])\n",
    "            path_for_image = 'dataset/train/' + stage_list[stage_id] + '/' + stage_list[stage_id] + \\\n",
    "                                '_' + psg_file.split(\"-\")[0] + '_' + str(start_time)\n",
    "\n",
    "            fig.savefig(path_for_image)\n",
    "            plt.close(fig)\n",
    "            ctrl_imgs[event_for_image[2] - 1] += 1\n",
    "\n",
    "    print(f'\\n Images have been prepared for {psg_file.split(\"-\")[0][0:-2]}. \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f02a102d-36a4-477d-9972-6084d4b34e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_grayscale(): # Not necessary, because argument color_mode in the keras.utils.image_dataset_from_directory helps to convert images in grayscale\n",
    "    path_for_image = \"dataset/train\"\n",
    "    for folder in os.listdir(path_for_image):\n",
    "        current = path_for_image + \"/\" + folder\n",
    "        files = os.listdir(current)\n",
    "        for file in files:\n",
    "            if file[0] == '.':\n",
    "                pass\n",
    "            else:\n",
    "                current_file_path = current + \"/\" + file\n",
    "                img = Image.open(current_file_path)\n",
    "                img = img.convert('L')\n",
    "                img.save(current_file_path)\n",
    "    print('========= Files have been converted. =========')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0c3280-c9bb-4903-878f-5375d660c6f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
